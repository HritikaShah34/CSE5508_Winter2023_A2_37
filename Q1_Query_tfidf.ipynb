{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "path = \"D://ir//assignment2//CSE508_Winter2023_Dataset\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "corpus = []\n",
    "for file in dir_list:\n",
    "    x = \"D://ir//assignment2//CSE508_Winter2023_Dataset//\"+file\n",
    "    with open(x, 'r') as file:\n",
    "        corpus.append(file.read())\n",
    "\n",
    "\n",
    "tokenized_corpus = [x.split() for x in corpus]\n",
    "\n",
    "unique_words = set(word for doc in tokenized_corpus for word in doc)\n",
    "sorted(unique_words)\n",
    "\n",
    "doc_freq = {word: sum(1 for doc in tokenized_corpus if word in doc)\n",
    "            for word in unique_words}\n",
    "\n",
    "\n",
    "idf = {word: math.log10(\n",
    "    len(corpus) / (1 + doc_freq[word])) for word in unique_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------BINARY------------------------------------------------------------------------------#\n",
    "output=[]\n",
    "words=[]\n",
    "for x in unique_words:\n",
    "    tfidf = []\n",
    "    for y1 in tokenized_corpus:\n",
    "        if x not in y1:\n",
    "            tfidf.append(0)\n",
    "        else:\n",
    "            tfidf.append(idf[x])\n",
    "    words.append(x)\n",
    "    output.append(tfidf)\n",
    "\n",
    "df = pd.DataFrame(output)\n",
    "df.index=words\n",
    "df.columns = range(1,len(df.columns)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244     356.111287\n",
       "1313    324.684752\n",
       "344     320.320448\n",
       "792     317.786113\n",
       "798     315.295384\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = []\n",
    "for i in tokenize:\n",
    "    row_1 = df.loc['{}'.format(i)]\n",
    "    list1.append(row_1)\n",
    "\n",
    "result=[]\n",
    "\n",
    "for i in range(len(list1)-1):\n",
    "    list1[i+1]=list1[i]+list1[i+1]\n",
    "\n",
    "ans=list1[i+1]\n",
    "a=ans.sort_values(ascending=False)\n",
    "a.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------RAW COUNT------------------------------------------------------------------#\n",
    "output=[]\n",
    "words=[]\n",
    "for x in unique_words:\n",
    "    tfidf = []\n",
    "    count = 0\n",
    "    for y1 in tokenized_corpus:\n",
    "        if x not in y1:\n",
    "            tfidf.append(0)\n",
    "        else:\n",
    "            tfidf.append(y1.count(x)*idf[x])\n",
    "    words.append(x)\n",
    "    output.append(tfidf)\n",
    "\n",
    "df = pd.DataFrame(output)\n",
    "df.index=words\n",
    "df.columns = range(1,len(df.columns)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1313    525.796354\n",
       "244     486.885918\n",
       "329     474.690180\n",
       "798     453.653180\n",
       "721     429.503045\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = []\n",
    "for i in tokenize:\n",
    "    row_1 = df.loc['{}'.format(i)]\n",
    "    list1.append(row_1)\n",
    "\n",
    "result=[]\n",
    "\n",
    "for i in range(len(list1)-1):\n",
    "    list1[i+1]=list1[i]+list1[i+1]\n",
    "\n",
    "ans1=list1[i+1]\n",
    "a1=ans1.sort_values(ascending=False)\n",
    "a1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------TERM FREQUENCY------------------------------------------------------------------------------#\n",
    "from collections import Counter\n",
    "output=[]\n",
    "words=[]\n",
    "for x in unique_words:\n",
    "    tfidf = []\n",
    "    for y1 in tokenized_corpus:\n",
    "        l = Counter(y1)\n",
    "        temp=0\n",
    "        for j in l:\n",
    "            temp = temp + l[j]\n",
    "        if x not in y1:\n",
    "            tfidf.append(0)\n",
    "        else:\n",
    "            tfidf.append((y1.count(x)/temp)*idf[x])\n",
    "    words.append(x)\n",
    "    output.append(tfidf)\n",
    "\n",
    "df = pd.DataFrame(output)\n",
    "df.index=words\n",
    "df.columns = range(1,len(df.columns)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995     2.669007\n",
       "471     2.669007\n",
       "718     2.153406\n",
       "1168    2.038724\n",
       "83      1.997140\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = []\n",
    "for i in tokenize:\n",
    "    row_1 = df.loc['{}'.format(i)]\n",
    "    list1.append(row_1)\n",
    "\n",
    "result=[]\n",
    "\n",
    "for i in range(len(list1)-1):\n",
    "    list1[i+1]=list1[i]+list1[i+1]\n",
    "\n",
    "ans=list1[i+1]\n",
    "a=ans.sort_values(ascending=False)\n",
    "a.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------LOG NORMALIZATION-----------------------------------------------------------------------------#\n",
    "from collections import Counter\n",
    "output=[]\n",
    "words=[]\n",
    "for x in unique_words:\n",
    "    tfidf = []\n",
    "    count1 = 0\n",
    "    for y1 in tokenized_corpus:\n",
    "        if x not in y1:\n",
    "            tfidf.append(0)\n",
    "        else:\n",
    "            tfidf.append((math.log10(y1.count(x)+1))*idf[x])\n",
    "    words.append(x)\n",
    "    output.append(tfidf)\n",
    "\n",
    "df = pd.DataFrame(output)\n",
    "df.index=words\n",
    "df.columns = range(1,len(df.columns)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244     123.066579\n",
       "1313    122.868240\n",
       "798     113.878077\n",
       "792     107.391047\n",
       "344     106.672923\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = []\n",
    "for i in tokenize:\n",
    "    row_1 = df.loc['{}'.format(i)]\n",
    "    list1.append(row_1)\n",
    "\n",
    "result=[]\n",
    "\n",
    "for i in range(len(list1)-1):\n",
    "    list1[i+1]=list1[i]+list1[i+1]\n",
    "\n",
    "ans=list1[i+1]\n",
    "a=ans.sort_values(ascending=False)\n",
    "a.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------DOUBLE NORMALIZATION------------------------------------------------------------------------------#\n",
    "from collections import Counter\n",
    "output=[]\n",
    "words=[]\n",
    "for x in unique_words:\n",
    "    tfidf = []\n",
    "    for y1 in tokenized_corpus:\n",
    "        l = Counter(y1)\n",
    "        max=0\n",
    "        for j in l:\n",
    "            if(max<l[j]):\n",
    "                max=l[j]\n",
    "        if x not in y1:\n",
    "            tfidf.append(0)\n",
    "        else:\n",
    "            tfidf.append((0.5 + (0.5 * (y1.count(x)/max)))*idf[x])\n",
    "    words.append(x)\n",
    "    output.append(tfidf)\n",
    "\n",
    "df = pd.DataFrame(output)\n",
    "df.index=words\n",
    "df.columns = range(1,len(df.columns)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244     193.270829\n",
       "344     192.767115\n",
       "792     191.575616\n",
       "798     180.330351\n",
       "1313    175.487285\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = []\n",
    "for i in tokenize:\n",
    "    row_1 = df.loc['{}'.format(i)]\n",
    "    list1.append(row_1)\n",
    "\n",
    "result=[]\n",
    "\n",
    "for i in range(len(list1)-1):\n",
    "    list1[i+1]=list1[i]+list1[i+1]\n",
    "\n",
    "ans=list1[i+1]\n",
    "a=ans.sort_values(ascending=False)\n",
    "a.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
